{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Defocus estimation using DenseNet 201\n",
    "\n",
    "DenseNet 201 is a CNN model developed by Cornell University, Tsinghua University, and Facebook AI Research in 2017.\n",
    "\n",
    "Keras documentation:\n",
    "[https://keras.io/api/applications/densenet/#densenet201-function](https://keras.io/api/applications/densenet/#densenet201-function)\n",
    "\n",
    "The original paper:\n",
    "[https://arxiv.org/pdf/1608.06993.pdf](https://arxiv.org/pdf/1608.06993.pdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Enables HiDPI rendering of matplotlib charts on Apple Retina displays.\n",
    "Comment out the line below if the matplotlib plots don’t look right on your computer.\n",
    "\"\"\"\n",
    "%config InlineBackend.figure_format = \"retina\"\n",
    "\n",
    "# Library imports\n",
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from dataset import Dataset\n",
    "from plot import Plot\n",
    "from mip import Microscopy_image_processor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download and extract the dataset if it’s not present.\n",
    "\n",
    "local_data_folder = os.path.join(os.path.abspath(os.getcwd()), \"data\")\n",
    "dataset_ulr = \"https://www.robots.ox.ac.uk/~vgg/data/dtd/download/dtd-r1.0.1.tar.gz\"\n",
    "\n",
    "Dataset.download_if_missing(local_data_folder, dataset_ulr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare the data\n",
    "\n",
    "import os\n",
    "import random\n",
    "from dataset import Dataset\n",
    "\n",
    "sample_side_size = 224\n",
    "training_set_percentage = 0.2\n",
    "\n",
    "all_features, all_labels = Dataset.get_features_and_labels(local_data_folder, sample_side_size)\n",
    "\n",
    "no_of_test_items = int(round(all_features.shape[0] * training_set_percentage))\n",
    "\n",
    "training_features = all_features[:-no_of_test_items]\n",
    "test_features = all_features[-no_of_test_items:]\n",
    "\n",
    "training_labels = all_labels[:-no_of_test_items]\n",
    "test_labels = all_labels[-no_of_test_items:]\n",
    "\n",
    "print(f\"all_features.shape: {all_features.shape}\")\n",
    "print(f\"labels.shape: {all_labels.shape}\")\n",
    "\n",
    "print(f\"training_features.shape: {training_features.shape}\")\n",
    "print(f\"training_labels.shape: {training_labels.shape}\")\n",
    "\n",
    "print(f\"test_features.shape: {test_features.shape}\")\n",
    "print(f\"test_labels.shape: {test_labels.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare the model: DenseNet201\n",
    "\n",
    "import keras\n",
    "from keras.applications import DenseNet201\n",
    "from keras.preprocessing import image\n",
    "from keras.models import Model\n",
    "from keras.layers import Dense, GlobalAveragePooling2D\n",
    "\n",
    "# Create the base pre-trained model\n",
    "base_model = DenseNet201(weights = None, include_top = False)\n",
    "\n",
    "# Add a global spatial average pooling layer\n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "# Let’s add a fully-connected layer\n",
    "x = Dense(1024, activation=\"relu\")(x)\n",
    "# And a logistic layer\n",
    "predictions = Dense(1, activation=\"sigmoid\")(x)\n",
    "\n",
    "# This is the model we will train\n",
    "model = Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer=\"rmsprop\", loss=\"mean_absolute_error\")\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model on the new data for a few epochs\n",
    "\n",
    "batch_size = 32\n",
    "epochs = 1\n",
    "\n",
    "history = model.fit(training_features, training_labels, validation_split = 0.33, epochs=epochs, batch_size = batch_size, verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training history\n",
    "\n",
    "metrics = history.history\n",
    "plt.figure(figsize=(11,3))\n",
    "plt.subplot(1,2,1)\n",
    "plt.plot(history.epoch, metrics[\"loss\"], metrics[\"val_loss\"])\n",
    "plt.legend([\"Loss (Training)\", \"Loss (Cross-validation)\"])\n",
    "plt.ylim([0, max(plt.ylim())])\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss (Mean absolute error)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the trained model against the test set\n",
    "\n",
    "model.evaluate(x = test_features, y = test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the trained model against three manually selected files \n",
    "\n",
    "p_files = [\"zigzagged_0014.jpg\", \"woven_0045.jpg\", \"veined_0150.jpg\"]\n",
    "p_weights = [0.9, 0.8, 0.7]\n",
    "p_prefix = \"densenet\"\n",
    "\n",
    "p_folder = os.path.join(os.path.abspath(os.getcwd()), \"predictions\")\n",
    "\n",
    "# Change to True to save the images\n",
    "save_images = False\n",
    "\n",
    "if save_images and not os.path.exists(p_folder):\n",
    "    os.mkdir(p_folder)\n",
    "\n",
    "for i, file in enumerate(p_files):\n",
    "    p_file_full_path = os.path.join(local_data_folder, file)\n",
    "    print(f\"Image {i+1}: {p_file_full_path}\\n\")\n",
    "    p_base = Dataset.get_single_sample(p_file_full_path, 0, sample_side_size)[0]\n",
    "    print(\"Base image:\")\n",
    "    if save_images:\n",
    "        Microscopy_image_processor.save_image(os.path.join(p_folder, f\"{p_prefix}_img{i+1}_base.jpg\"), p_base)\n",
    "    Plot.normalized_mono_image(p_base)\n",
    "\n",
    "    print(f\"Aberrated image. Actual weight: {p_weights[i]}\")\n",
    "    p_wrapped_sample = Dataset.get_single_sample(p_file_full_path, p_weights[i], sample_side_size)\n",
    "    p_sample = p_wrapped_sample[0]\n",
    "    if save_images:\n",
    "        Microscopy_image_processor.save_image(os.path.join(p_folder, f\"{p_prefix}_img{i+1}_abberated.jpg\"), p_sample)\n",
    "    Plot.normalized_mono_image(p_sample)\n",
    "\n",
    "    p_estimate = model.predict(p_wrapped_sample)[0][0]\n",
    "    p_delta = abs(p_weights[i] - p_estimate)\n",
    "    print(f\"Simulated focus correction. Absolute error: {p_delta}\")\n",
    "    p_corrected = Dataset.get_single_sample(p_file_full_path, p_delta, sample_side_size)[0]\n",
    "    if save_images:\n",
    "        Microscopy_image_processor.save_image(os.path.join(p_folder, f\"{p_prefix}_img{i+1}_corrected.jpg\"), p_corrected)\n",
    "    Plot.normalized_mono_image(p_corrected)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Absolute error of weight predictions\n",
    "\n",
    "for i, file in enumerate(p_files):\n",
    "    p_file_full_path = os.path.join(local_data_folder, file)\n",
    "    print(f\"Image {i+1}: {p_file_full_path}\\n\")\n",
    "    steps = []\n",
    "    errors = []\n",
    "    for step in np.linspace(0, 1, 21):\n",
    "        p_wrapped_sample = Dataset.get_single_sample(p_file_full_path, step, sample_side_size)\n",
    "        p_sample = p_wrapped_sample[0]\n",
    "        p_estimate = model.predict(p_wrapped_sample)[0][0]\n",
    "        steps.append(round(step, 5))\n",
    "        errors.append(abs(step - p_estimate))\n",
    "\n",
    "    plt.figure(figsize=(11, 3))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.xticks(np.arange(0, 1.2, 0.2))\n",
    "    plt.plot(steps, errors)\n",
    "    plt.legend([f\"Image {i+1}\"])\n",
    "    plt.ylim([0, 1])\n",
    "    plt.xlabel(\"Actual defocus weight\")\n",
    "    plt.ylabel(\"Absolute error\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulated re-focus behaviour of a microscope\n",
    "\n",
    "for i, file in enumerate(p_files):\n",
    "    p_file_full_path = os.path.join(local_data_folder, file)\n",
    "    print(f\"Image {i+1}: {p_file_full_path}\\n\")\n",
    "    print(f\"Initial defocus weight: {p_weights[i]}\")\n",
    "    last_weight = p_weights[i]\n",
    "    steps = []\n",
    "    estimates = []\n",
    "    errors = []\n",
    "    for step in range(11):\n",
    "        p_wrapped_sample = Dataset.get_single_sample(p_file_full_path, last_weight, sample_side_size)\n",
    "        p_sample = p_wrapped_sample[0]\n",
    "        steps.append(step)\n",
    "        errors.append(last_weight)\n",
    "        p_estimate = model.predict(p_wrapped_sample)[0][0]\n",
    "        estimates.append(p_estimate)\n",
    "        print(f\"Defocus estimate: {p_estimate}\")\n",
    "        last_weight = abs(last_weight - p_estimate)\n",
    "        print(f\"New defocus weight: {last_weight}\")\n",
    "\n",
    "    plt.figure(figsize=(11, 3))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.xticks(np.arange(0, 12, 1))\n",
    "    plt.plot(steps, errors, estimates)\n",
    "    plt.legend([\"Actual defocus weight\", \"Estimated defocus weight\"])\n",
    "    plt.ylim([0, 1])\n",
    "    plt.xlabel(\"Refocus step\")\n",
    "    plt.ylabel(\"Absolute error\")\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mini",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
